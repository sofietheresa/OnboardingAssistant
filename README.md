# ğŸ¤– Boardy - IBM Onboarding Assistant

Ein intelligenter Chat-Assistent fÃ¼r IBM-Standorte mit Watson X Integration.

## âœ¨ Features

- ğŸ¯ **Location-spezifisches Onboarding** - Angepasst an IBM-Standorte
- ğŸ¤– **Watson X Integration** - Nutzt IBMs fortschrittliche KI-Modelle
- ğŸ’» **Desktop-optimiert** - Professionelles, responsives Design
- ğŸ³ **Container-basiert** - Einfache Bereitstellung mit Podman

## ğŸš€ Quick Start

### 1. Voraussetzungen

- **WSL2** mit Ubuntu
- **Podman** und **podman-compose** in WSL
- **Watson X API-Zugang**

### 2. Installation

```bash
# Projekt klonen
git clone https://github.com/sofietheresa/OnboardingAssistant.git
cd OnboardingAssistant

# Umgebungsvariablen konfigurieren
cp env.example .env
# Bearbeiten Sie .env mit Ihren Watson X Credentials
```

### 3. Anwendung starten

```cmd
# Windows - Einfach doppelklicken oder ausfÃ¼hren:
run.bat
```

Das war's! ğŸ‰

## ğŸ“ Projektstruktur

```
boardy-onboarding-assistant/
â”œâ”€â”€ backend/                    # FastAPI Backend
â”‚   â”œâ”€â”€ app.py                 # Hauptanwendung
â”‚   â”œâ”€â”€ requirements.txt       # Python Dependencies
â”‚   â””â”€â”€ Dockerfile            # Container Definition
â”œâ”€â”€ frontend/                  # Frontend (fertig gebaut)
â”‚   â””â”€â”€ build/                # Produktive HTML/CSS/JS Dateien
â”œâ”€â”€ litellm-config.yaml       # Watson X Konfiguration
â”œâ”€â”€ podman-compose.yml        # Container Orchestrierung
â”œâ”€â”€ run.bat                   # Start/Restart Script
â”œâ”€â”€ env.example              # Umgebungsvariablen Vorlage
â””â”€â”€ README.md               # Diese Datei
```

## âš™ï¸ Konfiguration

Erstellen Sie eine `.env` Datei mit Ihren Watson X Credentials:

```env
WATSONX_API_KEY=your_actual_api_key
WATSONX_PROJECT_ID=your_actual_project_id
WATSONX_URL=https://us-south.ml.cloud.ibm.com
```

## ğŸŒ Zugriff

Nach dem Start ist die Anwendung verfÃ¼gbar unter:

- **Frontend**: http://localhost:8000
- **API**: http://localhost:8000/api/chat
- **Health Check**: http://localhost:8000/healthz

## ğŸ¤– VerfÃ¼gbare KI-Modelle

- **llama-3-8b** - Meta Llama 3 8B (Standard)
- **llama-3-70b** - Meta Llama 3 70B
- **granite-8b** - IBM Granite 3 8B
- **mistral-large** - Mistral Large
- **mixtral** - Mixtral 8x7B

## ğŸ¯ Standorte

- **IBM BÃ¶blingen** - Innovationszentrum fÃ¼r Cloud & AI
- **IBM MÃ¼nchen** - Enterprise Solutions & Consulting  
- **UDG Ludwigsburg** - Digital Business & Transformation

## ğŸ”§ Verwaltung

```bash
# Container Status prÃ¼fen
wsl --exec bash -c "cd /mnt/c/Users/SofiePischl/Documents/01_HdM/watsonx-chat-starter && podman-compose ps"

# Logs anzeigen
wsl --exec bash -c "cd /mnt/c/Users/SofiePischl/Documents/01_HdM/watsonx-chat-starter && podman-compose logs -f"

# Anwendung stoppen
wsl --exec bash -c "cd /mnt/c/Users/SofiePischl/Documents/01_HdM/watsonx-chat-starter && podman-compose down"
```

## ğŸ› Troubleshooting

### Container starten nicht
```bash
# Podman Status prÃ¼fen
wsl --exec podman info

# Logs prÃ¼fen
wsl --exec bash -c "cd /mnt/c/Users/SofiePischl/Documents/01_HdM/watsonx-chat-starter && podman-compose logs"
```

### API-Fehler
- ÃœberprÃ¼fen Sie Ihre Watson X Credentials in `.env`
- Stellen Sie sicher, dass Ihr Watson X Projekt aktiv ist

### Port-Konflikte
- Standard-Ports: 8000 (Frontend/API), 4000 (LiteLLM)
- Bei Konflikten Ã¤ndern Sie die Ports in `podman-compose.yml`

## ğŸ“ Lizenz

Dieses Projekt ist fÃ¼r Bildungs- und Entwicklungszwecke gedacht.

## ğŸ¤ Support

Bei Fragen oder Problemen erstellen Sie ein Issue im Repository.